---
title: "Bayesian A/B Testing in R \n"
author: Adam Rosenblit & David Denton
date: April 26, 2019
output:
  revealjs::revealjs_presentation:
    transition: slide
    theme: blood
    highlight: zenburn
    center: true
---
```{r, echo=FALSE}
htmltools::img(src = knitr::image_uri("logo4.png"), 
               alt = 'logo', 
               style = 'background:none; border:none; box-shadow:none; position:relative;')
```

### Company Overview
* Established in 2012
* Leading online widget supplier
* Excellent sales growth during first four years
* Sales began to decrease in 2016
    + Complicated web order form
    + Increasing number of orders from mobile devices
    
## Existing Sales Funnel
```{r message=FALSE, warning=FALSE, echo=FALSE}
library(tidyverse)
library(ggthemes)
gg <- read_csv('ab_data.csv') %>%
    filter(test_flag == 'pre_test') %>%
    group_by(page_name, page_num) %>%
    summarise(total_sessions = n_distinct(session_id)) %>%
    ungroup() %>%
    mutate(pct_total_sessions = total_sessions/max(total_sessions)) %>%
    ggplot(aes(x = reorder(page_name, page_num), y = pct_total_sessions, fill = as.factor(pct_total_sessions))) +
    geom_bar(stat = 'identity') +
    geom_text(nudge_y = .05, aes(label = paste0(round(pct_total_sessions*100, 2), '%')), size = 5) +
    theme_economist() + scale_fill_economist() +
    theme(legend.position = 'none') + theme(text= element_text(size = 14)) + 
    theme(axis.title = element_text(face = 'bold')) +
    xlab('Page Name') + ylab('Percent of Sessions') 
    
    
gg
```

***
```{r, echo=FALSE}
htmltools::img(src = knitr::image_uri("logo4.png"), 
               alt = 'logo', 
               style = 'background:none; border:none; box-shadow:none; position:relative;')
```

* The Problem
    + Conversion rate is low
    + Too many potential customers are lost
* The Solution
    + Develop a new buy-flow
    + Split site traffic between old & new buy-flows
    + Perform A/B test

***
```{r, echo=FALSE}
htmltools::img(src = knitr::image_uri("logo4.png"), 
               alt = 'logo', 
               style = 'background:none; border:none; box-shadow:none; position:relative;')
```

### Frequentist Approach
* Calcuate sample size using Power Test
* Calculate a point estimate of the conversion rate (sample proportion) for A and B
* Conduct test under the null hypothesis that the conversion rates are equal
* Hope that the resulting p-value < 0.05 so we can reject the null and therefore accept the alternative

***
```{r, echo=FALSE}
htmltools::img(src = knitr::image_uri("logo4.png"), 
               alt = 'logo', 
               style = 'background:none; border:none; box-shadow:none; position:relative;')
```  

### Bayesian Approach
* Encapsulate prior knowledge of conversion rate (ie, Find the conjugate prior distribution of the true parameter)
* Combine test data with prior knowledge to get the posterior distribution over the parameter
* Obtain direct probabilities of whether B is better than A (and by how much), and of the expected loss associated with choosing B over A

***
```{r, echo=FALSE}
htmltools::img(src = knitr::image_uri("logo4.png"), 
               alt = 'logo', 
               style = 'background:none; border:none; box-shadow:none; position:relative;')
```  

### Bayesian vs Frequentist Approach
* Instead of p-values you get direct probabilities on whether B is better than A (and by how much)
* Instead of point estimates your posterior distributions are parametrized random variables
* Bayesian tests are also immune to ‘peeking’ and are thus valid whenever a test is stopped

    
***

### So, how does the Bayes A/B test work?
* Find a conjugate prior for the parameter in question
    + Each visit is an _iid_ Bernoulli(p) trial
    + Therefore, the set of visits are Binomial(n,p),
    + The conjugate prior of the parameter of a Binomial _RV_ is the Beta Distribution
    + So, p ~ Beta($\alpha$$_{cp}$, $\beta$$_{cp}$)
    + Set $\alpha$$_{cp}$ = _conversions_ and $\beta$$_{cp}$ = _drop-offs_

***

### A little intuition behind $\alpha$$_{cp}$ and $\beta$$_{cp}$ 
* $\widehat{p}$ = conversions / (conversions + drop_offs)
* E($\widehat{p}$) = p
* When p ~ Beta($\alpha, \beta$), E(p) = $\alpha$ / ($\alpha$ + $\beta$)

***

### So, how does the Bayes A/B test work? (continued)   
* Use data collected for A and B to define the posterior distributions over their parameters 
    + $p_A$ ~ Beta($\alpha$$_A$ + $\alpha$$_{cp}$, $\beta$$_A$ + $\beta$$_{cp}$)
    + $p_B$ ~ Beta($\alpha$$_B$ + $\alpha$$_{cp}$, $\beta$$_B$ + $\beta$$_{cp}$)

***

### So, how does the Bayes A/B test work? (continued)   
* Conduct a MonteCarlo simulation using those posterior distributions
    + Draw n samples from $p_A$ and from $p_B$
    + Calculate P(B>A)
    + Calculate credible interval on (B-A)/A
    + Calculate posterior expected loss associated with choosing B over A

***
```{r, echo=FALSE}
htmltools::img(src = knitr::image_uri("logo4.png"), 
               alt = 'logo', 
               style = 'background:none; border:none; box-shadow:none; position:relative;')
```  

###Let's run some code!

***
## Our Conjugate Prior
```{r message=FALSE, warning=FALSE, echo=FALSE}
library(tidyverse)
library(bayesAB)
pretest_A <- read.csv('ab_data_session_grain.csv') %>% filter(test_flag=='pre_test' & webflow_id=='A')
get_stats <- function(x) {
    conversions <-sum(x)
    sample_size <- length(x)
    conversion_rate <- round(conversions/sample_size, 4)
    variance <- conversion_rate*(1-conversion_rate)/sample_size
    lower_95 <- round(conversion_rate - 1.96*sqrt(variance), 4)
    upper_95 <- round(conversion_rate + 1.96*sqrt(variance), 4)
    my_stats <- list(conversions = conversions, 
                     sample_size = sample_size,
                     conversion_rate = conversion_rate, 
                     variance = variance,
                     lower_95 = lower_95,
                     upper_95 = upper_95)
    return(my_stats)
}
pretest_A_stats <- get_stats(x=pretest_A$is_conversion)
prior_alpha <- pretest_A_stats$conversions
prior_beta <- pretest_A_stats$sample_size - pretest_A_stats$conversions
plot_beta <- plotBeta(alpha=prior_alpha, beta=prior_beta)
plot_beta + 
    geom_vline(xintercept=pretest_A_stats$lower_95, linetype='dashed', color = 'darkblue') +
    geom_vline(xintercept=pretest_A_stats$upper_95, linetype='dashed', color = 'darkblue') +
    geom_vline(xintercept=pretest_A_stats$conversion_rate, linetype='solid', color = 'darkred') +
    xlim(0.10, 0.15) +
    ggtitle(substitute(paste('Conjugate Prior: p ~ Beta(', alpha, '=', prior_alpha, ', ', beta, '=', prior_beta, ')'), list(prior_alpha=prior_alpha, prior_beta=prior_beta))) +
    theme(plot.title = element_text(hjust = 0.5))
```

***
## Bayes A/B Test Plots
```{r message=FALSE, warning=FALSE, echo=FALSE}
library(tidyverse)
library(bayesAB)
pretest_A <- read.csv('ab_data_session_grain.csv') %>% filter(test_flag=='pre_test' & webflow_id=='A')
test_A <-  read.csv('ab_data_session_grain.csv') %>% filter(test_flag=='test' & webflow_id=='A')
test_B <-  read.csv('ab_data_session_grain.csv') %>% filter(test_flag=='test' & webflow_id=='B')
get_stats <- function(x) {
    conversions <-sum(x)
    sample_size <- length(x)
    conversion_rate <- round(conversions/sample_size, 4)
    variance <- conversion_rate*(1-conversion_rate)/sample_size
    lower_95 <- round(conversion_rate - 1.96*sqrt(variance), 4)
    upper_95 <- round(conversion_rate + 1.96*sqrt(variance), 4)
    my_stats <- list(conversions = conversions, 
                     sample_size = sample_size,
                     conversion_rate = conversion_rate, 
                     variance = variance,
                     lower_95 = lower_95,
                     upper_95 = upper_95)
    return(my_stats)
}
pretest_A_stats <- get_stats(x=pretest_A$is_conversion)
test_A_stats <- get_stats(x=test_A$is_conversion)
test_B_stats <- get_stats(x=test_B$is_conversion)
prior_alpha <- pretest_A_stats$conversions
prior_beta <- pretest_A_stats$sample_size - pretest_A_stats$conversions
abTest <- bayesTest(test_A$is_conversion, 
                    test_B$is_conversion, 
                    priors = c('alpha' = prior_alpha, 'beta' = prior_beta), 
                    n_samples = 1e5, 
                    distribution = 'bernoulli')
plots <- plot(abTest)
posteriors <- plots$posteriors$Probability
posteriors + 
    ggtitle('Posterior Distributions of A and B') +
    theme(plot.title = element_text(hjust = 0.5))
```

***
## Bayes A/B Test Plots, continued
```{r message=FALSE, warning=FALSE, echo=FALSE}
library(tidyverse)
library(bayesAB)
pretest_A <- read.csv('ab_data_session_grain.csv') %>% filter(test_flag=='pre_test' & webflow_id=='A')
test_A <-  read.csv('ab_data_session_grain.csv') %>% filter(test_flag=='test' & webflow_id=='A')
test_B <-  read.csv('ab_data_session_grain.csv') %>% filter(test_flag=='test' & webflow_id=='B')
get_stats <- function(x) {
    conversions <-sum(x)
    sample_size <- length(x)
    conversion_rate <- round(conversions/sample_size, 4)
    variance <- conversion_rate*(1-conversion_rate)/sample_size
    lower_95 <- round(conversion_rate - 1.96*sqrt(variance), 4)
    upper_95 <- round(conversion_rate + 1.96*sqrt(variance), 4)
    my_stats <- list(conversions = conversions, 
                     sample_size = sample_size,
                     conversion_rate = conversion_rate, 
                     variance = variance,
                     lower_95 = lower_95,
                     upper_95 = upper_95)
    return(my_stats)
}
pretest_A_stats <- get_stats(x=pretest_A$is_conversion)
test_A_stats <- get_stats(x=test_A$is_conversion)
test_B_stats <- get_stats(x=test_B$is_conversion)
prior_alpha <- pretest_A_stats$conversions
prior_beta <- pretest_A_stats$sample_size - pretest_A_stats$conversions
abTest <- bayesTest(test_A$is_conversion, 
                    test_B$is_conversion, 
                    priors = c('alpha' = prior_alpha, 'beta' = prior_beta), 
                    n_samples = 1e5, 
                    distribution = 'bernoulli')
plots <- plot(abTest)
AliftoverB <- plots$samples$Probability
AliftoverB + 
    ggtitle('Histogram of (A-B)/B Sampled from Posteriors') +
    theme(plot.title = element_text(hjust = 0.5))
```

***
## Bayes A/B Test Summary
```{r message=FALSE, warning=FALSE, echo=FALSE}
library(tidyverse)
library(bayesAB)
pretest_A <- read.csv('ab_data_session_grain.csv') %>% filter(test_flag=='pre_test' & webflow_id=='A')
test_A <-  read.csv('ab_data_session_grain.csv') %>% filter(test_flag=='test' & webflow_id=='A')
test_B <-  read.csv('ab_data_session_grain.csv') %>% filter(test_flag=='test' & webflow_id=='B')
get_stats <- function(x) {
    conversions <-sum(x)
    sample_size <- length(x)
    conversion_rate <- round(conversions/sample_size, 4)
    variance <- conversion_rate*(1-conversion_rate)/sample_size
    lower_95 <- round(conversion_rate - 1.96*sqrt(variance), 4)
    upper_95 <- round(conversion_rate + 1.96*sqrt(variance), 4)
    my_stats <- list(conversions = conversions, 
                     sample_size = sample_size,
                     conversion_rate = conversion_rate, 
                     variance = variance,
                     lower_95 = lower_95,
                     upper_95 = upper_95)
    return(my_stats)
}
pretest_A_stats <- get_stats(x=pretest_A$is_conversion)
test_A_stats <- get_stats(x=test_A$is_conversion)
test_B_stats <- get_stats(x=test_B$is_conversion)
prior_alpha <- pretest_A_stats$conversions
prior_beta <- pretest_A_stats$sample_size - pretest_A_stats$conversions
abTest <- bayesTest(test_A$is_conversion, 
                    test_B$is_conversion, 
                    priors = c('alpha' = prior_alpha, 'beta' = prior_beta), 
                    n_samples = 1e5, 
                    distribution = 'bernoulli')
summary(abTest)
```

***
###Bayes A/B Test Summary, continued
* We are 0% certain that flow A is better than flow B, which implies B is better than A.
* In addition, we assert that the conversion rate for A is between -16.2% and -5.61% better (bigger) than that for B, implying B is defintiely better than A.
* The "posterior expected loss for choosing B over A" is 12.5%
    + "Based on the current winner, what is the expected loss you would see should you choose wrongly?"
    + Given that B is our current winner, we would expect to lose 12.5% in lift (think (B-A)/A percent life calculation)
if we choose A (the loser) over B (the winner).

***
```{r, echo=FALSE}
htmltools::img(src = knitr::image_uri("logo4.png"), 
               alt = 'logo', 
               style = 'background:none; border:none; box-shadow:none; position:relative;')
```  

###bayesAB can do so much more!
* We could also compare user interactions on two versions of a page 
    + interactions ~ Poisson($\lambda$)
    + then, $\lambda$ ~ Gamma($\alpha, \beta$)
* Then we could test the effect of increased/decreased interactions on conversion using the ```combine``` function


***
## Sales Funnels During Test
```{r message=FALSE, warning=FALSE, echo=FALSE}
library(tidyverse)
library(ggthemes)
gg <- read_csv('ab_data.csv') %>%
    filter(test_flag == 'test') %>%
    group_by(page_num, webflow_id) %>%
    summarise(total_sessions = n_distinct(session_id)) %>%
    ungroup() %>%
    group_by(webflow_id) %>%
    mutate(pct_total_sessions = total_sessions/max(total_sessions)) %>%
    ggplot(aes(x = page_num, y = pct_total_sessions, fill = as.factor(pct_total_sessions))) +
    geom_bar(stat = 'identity') +
    facet_wrap(vars(webflow_id)) +
    geom_text(nudge_y = .05, aes(label = paste0(round(pct_total_sessions*100, 2), '%')), size = 4) +
    theme_economist() + scale_fill_economist() +
    theme(legend.position = 'none') + theme(text= element_text(size = 14)) + 
    theme(axis.title = element_text(face = 'bold')) +
    xlab('Page Number') + ylab('Percent of Sessions')
    
    
gg
```

***
### Further Readings 
* https://cran.r-project.org/web/packages/bayesAB/vignettes/introduction.html
* https://github.com/FrankPortman/bayesAB/
* https://www.countbayesie.com/blog/2015/2/18/hans-solo-and-bayesian-priors
* https://www.countbayesie.com/blog/2015/4/25/bayesian-ab-testing
* http://varianceexplained.org/r/bayesian_ab_baseball/








